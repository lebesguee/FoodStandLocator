{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\129421425.py:2: DtypeWarning: Columns (59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  health_locations = pd.read_csv(filename)\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\3500236455.py:2: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  wholesale = pd.read_csv(filename)\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\2127765340.py:2: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  construction = pd.read_csv(filename)\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1436630130.py:2: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  goverment = pd.read_csv(filename)\n"
     ]
    }
   ],
   "source": [
    "%run ./1_DataIngestion.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Build dataframe with the ENOE foodstand location count aggregated by State and ZipCode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analize frecuency of words inside the type of foodstand\n",
    "#pd.Series(' '.join(denoe_puestos['nombre_act']).split()).value_counts()\n",
    "\n",
    "food_types = [\n",
    "    'tortas',\n",
    "    'tacos',\n",
    "    'antojitos',\n",
    "    'sodas',\n",
    "    'pizzas',\n",
    "    'hamburguesas',\n",
    "    'dogs',\n",
    "    'mariscos',\n",
    "    'corrida',\n",
    "    'pescados'\n",
    "    ]\n",
    "\n",
    "# Structure and standardize foodstand types\n",
    "denoe_puestos['FoodstandType'] = np.where(denoe_puestos.nombre_act.str.contains(\"tacos\"), \"Tacos\",\n",
    "                                 np.where(denoe_puestos.nombre_act.str.contains(\"antojitos\"), \"Antojitos\",\n",
    "                                 np.where(denoe_puestos.nombre_act.str.contains(\"pizzas\"), \"Pizza\",\n",
    "                                 np.where(denoe_puestos.nombre_act.str.contains(\"hamburguesas\"), \"Hamburguesas\",\n",
    "                                 np.where(denoe_puestos.nombre_act.str.contains(\"dogs\"), \"Hot-Dogs\",\n",
    "                                 np.where(denoe_puestos.nombre_act.str.contains(\"mariscos\"), \"Maricos\",\n",
    "                                 np.where(denoe_puestos.nombre_act.str.contains(\"pescados\"), \"Maricos\",\n",
    "                                np.where(denoe_puestos.nombre_act.str.contains(\"corrida\"), \"Comida Corrida\", \"Tortas\")))))))\n",
    "                                )\n",
    "\n",
    "# Aggregate foodstand count by State and ZipCode\n",
    "foodstandsByLocation = denoe_puestos.groupby(['entidad','cod_postal'])['FoodstandType'].count().reset_index(drop=False)\\\n",
    "                                 .rename(columns={\n",
    "                                                 'FoodstandType':'FoodstandCount',\n",
    "                                                 'entidad':'State',\n",
    "                                                 'cod_postal':'ZipCode'\n",
    "                                                 }\n",
    "                                        )\n",
    "\n",
    "# format zipcodes to string 5 characters\n",
    "foodstandsByLocation['ZipCode'] = foodstandsByLocation['ZipCode'].astype(str).apply(str).str.zfill(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Build a dataframe with State, Alcaldia and ZipCode info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep state, alcaldia and zipcode columns. drop duplicates\n",
    "tmp = pd.DataFrame().assign(State = inegi_zip_codes['d_estado'],\\\n",
    "                            Alcaldia = inegi_zip_codes['D_mnpio'],\\\n",
    "                            ZipCode = inegi_zip_codes['d_codigo']\\\n",
    "                            ).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "tmp['ZipCode'] = tmp['ZipCode'].apply(str).str.zfill(5) # ZipCode as string, left pad with 0, 5 digits zip codeformat\n",
    "\n",
    "# keep only a few alcaldias for start\n",
    "#top_alcaldias = ['Coyoacán', 'Álvaro Obregón', 'Benito Juárez', 'Cuauhtémoc', 'Miguel Hidalgo']\n",
    "#cdmx = tmp[tmp.Alcaldia.isin(top_alcaldias) & tmp.State.isin(['Ciudad de México'])]\n",
    "# cdmx = tmp[tmp.State.isin(['Ciudad de México'])]\n",
    "\n",
    "# save table\n",
    "states_and_zipcodes = tmp\n",
    "states_and_zipcodes.to_csv('../data/states_and_zipcodes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Aggregate health stabishments data by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring columns of interest\n",
    "health_locations = health_locations[[\n",
    "    'ID',\n",
    "    'NOMBRE DE LA UNIDAD',\n",
    "    'TOTAL DE CONSULTORIOS',\n",
    "    'TOTAL DE CAMAS',\n",
    "    'TIPO DE VIALIDAD',\n",
    "    'TIPO DE ASENTAMIENTO',\n",
    "    'NOMBRE DE LA ENTIDAD',\n",
    "    'CODIGO POSTAL',\n",
    "    'LATITUD',\n",
    "    'LONGITUD',\n",
    "    'ESTATUS DE OPERACION',\n",
    "    'ESTRATO UNIDAD'    \n",
    "    ]]\n",
    "\n",
    "health_locations.dropna(inplace=True) # bad data quality from source -> fast approach is to drop all NA values\n",
    "\n",
    "# format zipcodes to string 5 characters\n",
    "health_locations['CODIGO POSTAL'] = health_locations['CODIGO POSTAL'].astype(int).astype(str).apply(str).str.zfill(5)\n",
    "\n",
    "# group establishments by zip code\n",
    "healthByZipCode = health_locations.groupby(['CODIGO POSTAL'])['ID'].count().reset_index(drop=False)\\\n",
    "                                 .rename(columns={\n",
    "                                    'CODIGO POSTAL':'ZipCode',\n",
    "                                    'ID':'HealthStabishmentCount',\n",
    "                                    })\n",
    "# bring states into dataset\n",
    "healthByZipCode = pd.merge(healthByZipCode, states_and_zipcodes,  how='left', on='ZipCode')\n",
    "\n",
    "healthByZipCode.dropna(inplace=True) # drop NA's for ease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Aggregate count of wholesale commerce stabishments by zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring columns of interest\n",
    "wholesale = wholesale[[\n",
    "    'id',\n",
    "    'nom_estab',\n",
    "    'per_ocu',\n",
    "    'cod_postal',\n",
    "    'entidad'\n",
    "    ]]\n",
    "\n",
    "wholesale.dropna(inplace=True) # bad data quality from source -> fast approach is to drop all NA values\n",
    "\n",
    "# format zipcodes to string 5 characters\n",
    "wholesale['cod_postal'] = wholesale['cod_postal'].astype(str).apply(str).str.zfill(5)\n",
    "\n",
    "wholesale = wholesale.groupby(['entidad', 'cod_postal']).agg({\n",
    "                        'id' : 'count',\n",
    "                        'per_ocu' : 'mean'\n",
    "                        })\\\n",
    "                        .reset_index(drop=False)\\\n",
    "                        .rename(columns={\n",
    "                                    'id':'Wholesale_StabishmentCount',\n",
    "                                    'per_ocu':'Wholesale_AverageFlux',\n",
    "                                    'entidad':'State',\n",
    "                                    'cod_postal':'ZipCode'\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Aggregate count of construction industry stabishments by zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring columns of interest\n",
    "construction = construction[[\n",
    "    'id',\n",
    "    'nom_estab',\n",
    "    'per_ocu',\n",
    "    'cod_postal',\n",
    "    'entidad'\n",
    "    ]]\n",
    "\n",
    "construction.dropna(inplace=True) # bad data quality from source -> fast approach is to drop all NA values\n",
    "\n",
    "# format zipcodes to string 5 characters\n",
    "construction['cod_postal'] = construction['cod_postal'].astype(str).apply(str).str.zfill(5)\n",
    "\n",
    "construction = construction.groupby(['entidad', 'cod_postal']).agg({\n",
    "                        'id' : 'count',\n",
    "                        'per_ocu' : 'mean'\n",
    "                        })\\\n",
    "                        .reset_index(drop=False)\\\n",
    "                        .rename(columns={\n",
    "                                    'id':'Construction_StabishmentCount',\n",
    "                                    'per_ocu':'Construction_AverageFlux',\n",
    "                                    'entidad':'State',\n",
    "                                    'cod_postal':'ZipCode'\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Aggregate count of corporates centres by zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring columns of interest\n",
    "corporate = corporate[[\n",
    "    'id',\n",
    "    'nom_estab',\n",
    "    'per_ocu',\n",
    "    'cod_postal',\n",
    "    'entidad'\n",
    "    ]]\n",
    "\n",
    "corporate.dropna(inplace=True) # bad data quality from source -> fast approach is to drop all NA values\n",
    "\n",
    "# format zipcodes to string 5 characters\n",
    "corporate['cod_postal'] = corporate['cod_postal'].astype(str).apply(str).str.zfill(5)\n",
    "\n",
    "corporate = corporate.groupby(['entidad', 'cod_postal']).agg({\n",
    "                        'id' : 'count',\n",
    "                        'per_ocu' : 'mean'\n",
    "                        })\\\n",
    "                        .reset_index(drop=False)\\\n",
    "                        .rename(columns={\n",
    "                                    'id':'Corporate_StabishmentCount',\n",
    "                                    'per_ocu':'Corporate_AverageFlux',\n",
    "                                    'entidad':'State',\n",
    "                                    'cod_postal':'ZipCode'\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Aggregate count of education centres by zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring columns of interest\n",
    "education = education[[\n",
    "    'id',\n",
    "    'nom_estab',\n",
    "    'per_ocu',\n",
    "    'cod_postal',\n",
    "    'entidad'\n",
    "    ]]\n",
    "\n",
    "education.dropna(inplace=True) # bad data quality from source -> fast approach is to drop all NA values\n",
    "\n",
    "# format zipcodes to string 5 characters\n",
    "education['cod_postal'] = education['cod_postal'].astype(str).apply(str).str.zfill(5)\n",
    "\n",
    "education = education.groupby(['entidad', 'cod_postal']).agg({\n",
    "                        'id' : 'count',\n",
    "                        'per_ocu' : 'mean'\n",
    "                        })\\\n",
    "                        .reset_index(drop=False)\\\n",
    "                        .rename(columns={\n",
    "                                    'id':'Education_StabishmentCount',\n",
    "                                    'per_ocu':'Education_AverageFlux',\n",
    "                                    'entidad':'State',\n",
    "                                    'cod_postal':'ZipCode'\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Aggregate count of goverment centres by zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring columns of interest\n",
    "goverment = goverment[[\n",
    "    'id',\n",
    "    'nom_estab',\n",
    "    'per_ocu',\n",
    "    'cod_postal',\n",
    "    'entidad'\n",
    "    ]]\n",
    "\n",
    "goverment.dropna(inplace=True) # bad data quality from source -> fast approach is to drop all NA values\n",
    "\n",
    "# format zipcodes to string 5 characters\n",
    "goverment['cod_postal'] = goverment['cod_postal'].astype(str).apply(str).str.zfill(5)\n",
    "\n",
    "goverment = goverment.groupby(['entidad', 'cod_postal']).agg({\n",
    "                        'id' : 'count',\n",
    "                        'per_ocu' : 'mean'\n",
    "                        })\\\n",
    "                        .reset_index(drop=False)\\\n",
    "                        .rename(columns={\n",
    "                                    'id':'Goverment_StabishmentCount',\n",
    "                                    'per_ocu':'Goverment_AverageFlux',\n",
    "                                    'entidad':'State',\n",
    "                                    'cod_postal':'ZipCode'\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-1. Enrich ENOE's Foodstand information with INEGI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1313774910.py:13: FutureWarning: Passing 'suffixes' which cause duplicate columns {'State_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = pd.merge(df, construction,  how='left', on='ZipCode')\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1313774910.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Construction_StabishmentCount'].fillna(value=df['Construction_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1313774910.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Construction_AverageFlux'].fillna(value=df['Construction_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1313774910.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Corporate_StabishmentCount'].fillna(value=df['Corporate_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1313774910.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Corporate_AverageFlux'].fillna(value=df['Corporate_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1313774910.py:25: FutureWarning: Passing 'suffixes' which cause duplicate columns {'State_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df = pd.merge(df, education,  how='left', on='ZipCode')\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1313774910.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Education_StabishmentCount'].fillna(value=df['Education_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1313774910.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Education_AverageFlux'].fillna(value=df['Education_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1313774910.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Goverment_StabishmentCount'].fillna(value=df['Goverment_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
      "C:\\Users\\mike_\\AppData\\Local\\Temp\\ipykernel_4136\\1313774910.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Goverment_AverageFlux'].fillna(value=df['Goverment_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n"
     ]
    }
   ],
   "source": [
    "# merge health centres\n",
    "df = pd.merge(foodstandsByLocation, healthByZipCode,  how='left', on='ZipCode')\n",
    "#df.dropna(inplace=True)\n",
    "df['HealthStabishmentCount'].fillna(value=df['HealthStabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
    "\n",
    "# merge wholesale centres\n",
    "df = pd.merge(df, wholesale,  how='left', on='ZipCode')\n",
    "#df.dropna(inplace=True)\n",
    "df['Wholesale_StabishmentCount'].fillna(value=df['Wholesale_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
    "df['Wholesale_AverageFlux'].fillna(value=df['Wholesale_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
    "\n",
    "# merge construction centres\n",
    "df = pd.merge(df, construction,  how='left', on='ZipCode')\n",
    "#df.dropna(inplace=True)\n",
    "df['Construction_StabishmentCount'].fillna(value=df['Construction_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
    "df['Construction_AverageFlux'].fillna(value=df['Construction_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
    "\n",
    "# merge corporate centres\n",
    "df = pd.merge(df, corporate,  how='left', on='ZipCode')\n",
    "#df.dropna(inplace=True)\n",
    "df['Corporate_StabishmentCount'].fillna(value=df['Corporate_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
    "df['Corporate_AverageFlux'].fillna(value=df['Corporate_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
    "\n",
    "# merge education centres\n",
    "df = pd.merge(df, education,  how='left', on='ZipCode')\n",
    "#df.dropna(inplace=True)\n",
    "df['Education_StabishmentCount'].fillna(value=df['Education_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
    "df['Education_AverageFlux'].fillna(value=df['Education_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
    "\n",
    "# merge goverment centres\n",
    "df = pd.merge(df, goverment,  how='left', on='ZipCode')\n",
    "#df.dropna(inplace=True)\n",
    "df['Goverment_StabishmentCount'].fillna(value=df['Goverment_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
    "df['Goverment_AverageFlux'].fillna(value=df['Goverment_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N. Consolidate final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df\n",
    "\n",
    "# Drop columns based on column index.\n",
    "final_df = final_df.drop(final_df.columns[[0, 4, 6, 9, 12, 15]],axis = 1)\n",
    "\n",
    "# arrange column order\n",
    "final_df = final_df[[\n",
    "                    'State',\n",
    "                    'Alcaldia',\n",
    "                    'ZipCode',\n",
    "                    'FoodstandCount',\n",
    "                    'HealthStabishmentCount',\n",
    "                    'Wholesale_StabishmentCount',\n",
    "                    'Wholesale_AverageFlux',\n",
    "                    'Construction_StabishmentCount',\n",
    "                    'Construction_AverageFlux',\n",
    "                    'Corporate_StabishmentCount',\n",
    "                    'Corporate_AverageFlux',\n",
    "                    'Education_StabishmentCount',\n",
    "                    'Education_AverageFlux',\n",
    "                    'Goverment_StabishmentCount',\n",
    "                    'Goverment_AverageFlux'\n",
    "                    ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Construction_StabishmentCount'].fillna(value=final_df['Construction_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
    "final_df['Construction_AverageFlux'].fillna(value=final_df['Construction_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
    "\n",
    "final_df['Corporate_StabishmentCount'].fillna(value=final_df['Corporate_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
    "final_df['Corporate_AverageFlux'].fillna(value=final_df['Corporate_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
    "\n",
    "final_df['Education_StabishmentCount'].fillna(value=final_df['Education_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
    "final_df['Education_AverageFlux'].fillna(value=final_df['Education_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
    "\n",
    "final_df['Goverment_StabishmentCount'].fillna(value=final_df['Goverment_StabishmentCount'].mean(), inplace=True) # Input mean to NA's values\n",
    "final_df['Goverment_AverageFlux'].fillna(value=final_df['Goverment_AverageFlux'].mean(), inplace=True) # Input mean to NA's values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "777a9814b1f625c6de01a68afd34302da90c24c55ff64ad7426d28deb82a847b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
